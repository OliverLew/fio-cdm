#!/usr/bin/env python
import os
import sys
import json
import argparse
import logging
import configparser
import subprocess

logging.basicConfig(level=os.environ.get("LOGLEVEL", "INFO"), format="%(message)s")


def readable2byte(num):
    units = {'k': 1, 'm': 2, 'g': 3, 't': 4}
    num = num.lower().rstrip("b").rstrip("i")
    if num[-1] in units.keys():
        return int(num[:-1]) * 1024 ** units[num[-1]]
    elif num[-1].isdigit():
        return int(num)
    else:
        logging.error("Unrecognised size: %s(i)B. Largest unit available is TiB", num.upper())
        exit(1)


def byte2readable(num):
    for unit in ['', 'Ki', 'Mi', 'Gi']:
        if abs(num) < 1024.0:
            return "%3.1f%sB" % (num, unit)
        num /= 1024.0
    return "%.1f%sB" % (num, 'Ti')


class Job:
    def __init__(self, size, directory):
        self.jobs = []
        self.bandwidth = {}
        self._jobfile_name = 'jobfile'
        self._testfile_name = '.fio_testmark'
        self.config = configparser.ConfigParser(allow_no_value=True)
        self.config.read_dict({
            'global': {
                'ioengine': 'libaio',
                'runtime': '25',
                'ramp_time': '5',
                'size': size,
                'filename': self._testfile_name,
                'directory': directory,
                'direct': '1',
                'refill_buffers': None,
                'norandommap': None,
                'randrepeat': '0',
                'allrandrepeat': '0',
                'group_reporting': None
            }
        })

    def _jobname_templ(self, job):
        return "{}-{{rw}}-{}-Q{}-T{}".format(job["rw"].title(), job["bs"], job["q"], job["t"])

    def _displayname(self, job):
        return "{}{} Q{:2}T{:2}".format(job["rw"], job["bs"], str(job["q"]), str(job["t"])).upper()

    def _create_jobfile(self, jobfile):
        if jobfile == '-':
            self.config.write(sys.stdout, space_around_delimiters=False)
        else:
            with open(jobfile, 'w') as f:
                self.config.write(f, space_around_delimiters=False)

    def create_job(self, rw_type, queue_size, thread_num):
        if rw_type == 'seq':
            blocksize = '1m' 
        elif rw_type == 'rnd':
            blocksize = '4k'
        else:
            logging.error("Job rw type only accepts \"seq\" and \"rnd\"")
            exit(1)

        job = {"rw": rw_type, "bs": blocksize, "q": queue_size, "t": thread_num}
        self.jobs.append(job)

        if args.mix == 0:
            rw_name_type = [("Read","read"), ("Write", "write")]
        else:
            rw_name_type = [("Read","read"), ("Write", "write"), ("Mix", "rw")]

        for name, rw in rw_name_type:
            self.config.read_dict({
                self._jobname_templ(job).format(rw=name): {
                    'bs': blocksize,
                    'rw': rw if rw_type == 'seq' else 'rand' + rw,
                    'rwmixread': args.mix,
                    'iodepth': queue_size,
                    'numjobs': thread_num,
                    'loops': args.number,
                    'stonewall': None
                }
            })

    def run(self):
        if not self._check_disk_space():
            exit(1)

        if args.dump_jobfile:
            self._create_jobfile(args.dump_jobfile)
            exit()
        else:
            self._create_jobfile(self._jobfile_name)

        try:
            output = subprocess.check_output(['fio', '--output-format', 'json', self._jobfile_name])
        except KeyboardInterrupt:
            logging.info('interrupted, cleaning up before exit...')
            exit(1)
        finally:
            os.remove(os.path.join(args.target, self._jobfile_name))
            os.remove(os.path.join(args.target, self._testfile_name))

        logging.debug(output.decode('utf-8'))
        info = json.loads(output)

        # Unit of I/O speed, use MB/s(10^6) instead of MiB/s(2^30).
        unit = 10**6

        # TODO: don't feel right about this way of storing data
        for job in info['jobs']:
            rw = job['job options']['rw']
            if rw == 'read' or rw == 'randread':
                self.bandwidth[job['jobname']] = job['read']['bw_bytes'] / unit
            if rw == 'write' or rw == 'randwrite':
                self.bandwidth[job['jobname']] = job['write']['bw_bytes'] / unit
            if rw == 'rw' or rw == 'randrw':
                self.bandwidth[job['jobname']] = (job['read']['bw_bytes'] * args.mix +
                                                  job['write']['bw_bytes'] * (100.0 - args.mix)) / 100.0 / unit

    def print_result(self):
        if args.mix:
            print("|Name        | Read  | Write |  Mix  |\n"
                  "|------------|-------|-------|-------|")
            template_row = "|{jobname}|{read:7.2f}|{write:7.2f}|{mix:7.2f}|"
        else:
            print("|Name        | Read  | Write |\n"
                  "|------------|-------|-------|")
            template_row = "|{jobname}|{read:7.2f}|{write:7.2f}|"

        for job in self.jobs:
            jobname = self._jobname_templ(job)
            print(template_row.format(
                jobname=self._displayname(job),
                read=self.bandwidth[jobname.format(rw="Read")],
                write=self.bandwidth[jobname.format(rw="Write")],
                mix=self.bandwidth.get(jobname.format(rw="Mix"))
            ))

    def _check_disk_space(self):
        statvfs = os.statvfs(args.target)
        avail = statvfs.f_frsize * statvfs.f_bfree
        needed = readable2byte(args.size)

        if avail > needed:
            return True
        else:
            logging.warning("Not enough space available in %s:", args.target)
            logging.warning("Needed: %s. Available: %s", byte2readable(needed), byte2readable(avail))
            return False


def get_parser():
    parser = argparse.ArgumentParser(
            formatter_class=argparse.RawDescriptionHelpFormatter,
            description='A python script to show disk test results with fio',
            epilog='''
Note:
    Do not add argument <target> after -x (as in \"fio-cdm -x <target>\"), \
it will be regarded as <mix> but an error will pop up since -x optionally \
needs a number.

Examples:
    Set test file size to 512MB, run 5 times with read, write and mix tests \
(specify the mix percentage to be 60%):
        fio-cdm -s 512m -n 5 -x 60

    Manually add jobs:
        fio-cdm -a seq,1,1 seq,32,1 rnd,16,8

    Show the equivalent command directly with fio:
        fio-cdm -f - | fio --showcmd -
''')

    parser.add_argument('target', default='.',
                        help='The path of the directory to test')
    parser.add_argument('-n', metavar='number', dest='number', type=int, default=1,
                        help='''Number of tests, default is 1''')
    parser.add_argument('-s', metavar='size', dest='size', default='1G',
                        help='''The size of file I/O, same as the fio parameter, default is 1G''')
    parser.add_argument('-x', metavar='mix', dest='mix', type=float, nargs="?", const=70, default=0,
                        help='''Add mixed rw test, default is disabled. <mix> is read percentage, default is 70.''')
    parser.add_argument('-a', metavar='job', dest='jobs', nargs="+",
                        help='''Manually add multiple jobs. Override default. Format is \"seq|rnd,queue depth,thread number\".''')
    parser.add_argument('-f', metavar='dump-jobfile', dest='dump_jobfile',
                        help='''Save jobfile and quit without running fio. Use \'-\' to print to stdout.''')
    return parser


if __name__ == '__main__':
    # TODO: realtime visual feedback, with fio --debug=io, hard
    # TODO: time upper limit do this with 'runtime'
    # TODO: show iops or latency
    parser = get_parser()
    args = parser.parse_args()
    logging.debug(args)

    fio_job = Job(args.size, args.target)
    if args.jobs:
        for job in args.jobs:
            rw_type, qd, tn = job.split(',')
            fio_job.create_job(rw_type, int(qd), int(tn))
    else:
        fio_job.create_job('seq', 32, 1)
        fio_job.create_job('rnd', 8,  8)
        fio_job.create_job('rnd', 32, 1)
        fio_job.create_job('rnd', 1,  1)

    fio_job.run()
    fio_job.print_result()
