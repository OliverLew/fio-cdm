#!/usr/bin/env python
import os
import sys
import json
import shutil
import argparse
import logging
import configparser
import subprocess


def readable2byte(num):
    """[K|M|G|T](i)B -> byte, regard the multiply as 1024"""
    units = {'k': 1, 'm': 2, 'g': 3, 't': 4}
    num = num.lower().rstrip("b").rstrip("i")
    if num[-1] in units.keys():
        return int(num[:-1]) * 1024 ** units[num[-1]]
    elif num[-1].isdigit():
        return int(num)
    else:
        logging.error("Unrecognised size: %s(i)B. Largest unit available is TiB", num.upper())
        exit(1)


def byte2readable(num):
    """byte -> [K|M|G|T]iB"""
    for unit in ['', 'Ki', 'Mi', 'Gi']:
        if abs(num) < 1024.0:
            return "%3.1f%sB" % (num, unit)
        num /= 1024.0
    return "%.1f%sB" % (num, 'Ti')


class Job:
    def __init__(self):
        self.jobs = []
        self._jobfile_name = 'jobfile'
        self._testfile_name = '.fio_testmark'
        self.blocksize = {'seq': '1m', 'rnd': '4k'}
        self.config = configparser.ConfigParser(allow_no_value=True)
        self.config.read_dict({
            'global': {
                'ioengine': 'windowsaio' if os.name == 'nt' else 'libaio',
                'filename': self._testfile_name,
                'directory': args.target,
                'size': args.size,
                'direct': '1',
                # borrowed configuration from shell version
                'runtime': '25',
                'ramp_time': '5',
                'refill_buffers': None,
                'norandommap': None,
                'randrepeat': '0',
                'allrandrepeat': '0',
                'group_reporting': None
            }
        })
        if args.zero_buffers:
            self.config.read_dict({ 'global': { 'zero_buffers': None } })
        # Windows does not support pthread mutexes
        if os.name == 'nt':
            self.config.read_dict({ 'global': { 'thread': None } })

    def _jobname_templ(self, job):
        return "{}-{{rw}}-{}-q{}-t{}".format(job["rw"], job["bs"], job["q"], job["t"])

    def _displayname(self, job):
        return "{}{} Q{:2}T{:2}".format(job["rw"], job["bs"], str(job["q"]), str(job["t"])).upper()

    def _create_jobfile(self, jobfile):
        if jobfile == '-':
            self.config.write(sys.stdout, space_around_delimiters=False)
        else:
            with open(jobfile, 'w') as f:
                self.config.write(f, space_around_delimiters=False)

    def create_job(self, rw_type, queue_size, thread_num):
        try:
            blocksize = self.blocksize[rw_type]
        except KeyError:
            logging.error("Job rw type only accepts \"seq\" and \"rnd\"")
            exit(1)

        job = {"rw": rw_type, "bs": blocksize, "q": queue_size, "t": thread_num}
        self.jobs.append(job)

        rw_types = ["read", "write"]
        if args.mix:
            rw_types.append("rw")

        # TODO: nameing for seq/rnd and r/w/x
        for rw in rw_types:
            self.config.read_dict({
                self._jobname_templ(job).format(rw=rw): {
                    'rw': rw if rw_type == 'seq' else 'rand' + rw,
                    'bs': blocksize,
                    'rwmixread': args.mix,
                    'iodepth': queue_size,
                    'numjobs': thread_num,
                    'loops': args.number,
                    'stonewall': None
                }
            })

    def run(self):
        if not self._check_disk_space():
            exit(1)

        if args.dump_jobfile:
            self._create_jobfile(args.dump_jobfile)
            exit()
        else:
            self._create_jobfile(self._jobfile_name)

        try:
            output = subprocess.check_output(['fio', '--output-format', 'json', self._jobfile_name])
        except KeyboardInterrupt:
            logging.info('interrupted, cleaning up before exit...')
            exit()
        finally:
            if os.path.exists(self._jobfile_name):
                os.remove(self._jobfile_name)
            if os.path.exists(os.path.join(args.target, self._testfile_name)):
                os.remove(os.path.join(args.target, self._testfile_name))

        fio_output = json.loads(output)
        info = {job.pop("jobname"): job for job in fio_output["jobs"]}
        logging.debug(info)

        self._print_result(info)

    def _print_result(self, info):
        def _print_result_line(job, name, f):
            jobname_templ = self._jobname_templ(job)
            read=info.get(jobname_templ.format(rw="read"))
            write=info.get(jobname_templ.format(rw="write"))
            mix=info.get(jobname_templ.format(rw="rw"))
            print(template_row.format(
                jobname=name,
                read=f(read['read']),
                write=f(write['write']),
                mix=None if args.mix == 0 else (f(mix['read']) * args.mix +
                    f(mix['write']) * (100 - args.mix)) / 100.0
            ))

        if args.mix:
            print("|Name        | Read(MB/s)|Write(MB/s)|  Mix(MB/s)|\n"
                  "|------------|-----------|-----------|-----------|")
            template_row = "|{jobname}|{read:11.2f}|{write:11.2f}|{mix:11.2f}|"
        else:
            print("|Name        | Read(MB/s)|Write(MB/s)|\n"
                  "|------------|-----------|-----------|")
            template_row = "|{jobname}|{read:11.2f}|{write:11.2f}|"

        for job in self.jobs:
            _print_result_line(job, self._displayname(job), lambda d: d['bw_bytes'] / 10**6)
            if job['rw'] == 'rnd':
                _print_result_line(job, "... IOPS    ", lambda d: d['iops'])
                _print_result_line(job, "... latency ", lambda d: d['lat_ns']['mean'] / 1000)

    def _check_disk_space(self):
        avail = shutil.disk_usage(args.target).free
        needed = readable2byte(args.size)

        if avail > needed:
            return True
        else:
            logging.warning("Not enough space available in %s:", args.target)
            logging.warning("Needed: %s. Available: %s", byte2readable(needed), byte2readable(avail))
            return False


def get_parser():
    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description='A python script to show disk test results with fio',
        epilog=
            'Note:\n'
            '    Do not add argument <target> right after -x (as in \"fio-cdm -x <target>\").\n\n'
            'Examples:\n'
            '    Set test file size to 512MB, 5 test runs with read, write and mix tests:\n'
            '        fio-cdm -s 512m -n 5 -x\n\n'
            '    Manually add jobs to replace the default ones:\n'
            '        fio-cdm -a seq,1,1 seq,32,1 rnd,16,8\n\n'
            '    Show the equivalent command directly with fio (without running the test):\n'
            '        fio-cdm -f - | fio --showcmd -\n'
        )

    parser.add_argument('target', nargs='?', default='.',
                        help='The path of the directory to test, default to current directory.')
    parser.add_argument('-n', metavar='number', dest='number', type=int, default=1,
                        help='Number of tests, default is 1.')
    parser.add_argument('-s', metavar='size', dest='size', default='1G',
                        help='The size of file I/O, same as the fio parameter, default is 1G.')
    parser.add_argument('-x', metavar='mix', dest='mix', type=float, nargs="?", const=70, default=0,
                        help='Add mixed rw test, default is disabled. <mix> is read percentage, default is 70 if not specified.')
    parser.add_argument('-0', dest='zero_buffers', action='store_true',
                        help='Initialize buffers with zeros instead of random data')
    parser.add_argument('-a', metavar='job', dest='jobs', nargs="+",
                        help='Manually add multiple jobs. Override default. Format is \"seq|rnd,<queue depth>,<thread number>\".')
    parser.add_argument('-f', metavar='dump-jobfile', dest='dump_jobfile',
                        help='Save jobfile and quit without running fio. Use \'-\' to print to stdout.')
    # hidden option, enable to show debug information
    parser.add_argument('-g', dest='debug', action='store_true', help=argparse.SUPPRESS)
    return parser


if __name__ == '__main__':
    # TODO: real-time visual feedback, with fio --debug=io, hard
    # TODO: time upper limit do this with 'runtime'
    # TODO: interval time
    # TODO: vendor and model with lsblk -o +VENDOR,MODEL or /sys/block/*/device/{vendor,model}
    # TODO: print summary
    # TODO: possibly specify block size in args?
    # TODO: windows specify device
    # Unit of I/O speed, use MB/s(10^6) instead of MiB/s(2^30).
    parser = get_parser()
    args = parser.parse_args()
    logging.basicConfig(level=logging.DEBUG if args.debug else logging.INFO, format="%(message)s")

    logging.debug(args)

    fio_job = Job()
    if args.jobs:
        for job in args.jobs:
            rw_type, qd, tn = job.split(',')
            fio_job.create_job(rw_type, int(qd), int(tn))
    else:
        fio_job.create_job('seq',  8,  1)
        fio_job.create_job('seq',  1,  1)
        fio_job.create_job('rnd', 32, 16)
        fio_job.create_job('rnd',  1,  1)
    fio_job.run()
